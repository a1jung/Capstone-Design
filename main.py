import os, json, re, textwrap
from typing import Dict, List
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles

# OpenAI optional
try:
    import openai
except:
    openai = None

app = FastAPI()

# =============================
# ğŸ“Œ í•œêµ­ì–´ â†’ ì˜ì–´ ê²€ìƒ‰ í™•ì¥ ì‚¬ì „
# =============================
KOR_TO_ENG = {
    "ìš”íŠ¸": ["yacht", "laser", "470"],
    "ì„¸ì¼ë§": ["yacht"],
    "ë ˆì´ì €": ["laser"],
    "ì•¼êµ¬": ["baseball", "pitcher", "catcher", "infielder", "outfielder"],
    "íˆ¬ìˆ˜": ["pitcher"],
    "í¬ìˆ˜": ["catcher"],
    "íƒ€ì": ["batter"],
    "ë‚´ì•¼": ["infielder"],
    "ì™¸ì•¼": ["outfielder"],
    "ì²´ì¡°": ["gymnastics"],
    "ê¸°ê³„ì²´ì¡°": ["gymnastics"],
    "í‰í–‰ë´‰": ["parallel bars"],
    "ë§ˆë£¨": ["floor"],
    "ë„ë§ˆ": ["vault"],
    "ë§": ["rings"],
}

def expand_korean_query(q: str) -> str:
    """í•œêµ­ì–´ ì§ˆë¬¸ì„ ì˜ì–´ í‚¤ì›Œë“œê¹Œì§€ í™•ì¥"""
    result = [q]
    for kor, eng_list in KOR_TO_ENG.items():
        if kor in q:
            result.extend(eng_list)
    return " ".join(result)


# =============================
# ê²½ë¡œ ì„¤ì •
# =============================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
TEMPLATES_DIR = os.path.join(BASE_DIR, "templates")
STATIC_DIR = os.path.join(BASE_DIR, "static")

if os.path.exists(STATIC_DIR):
    app.mount("/static", StaticFiles(directory=STATIC_DIR), name="static")

# =============================
# KB ë¡œë“œ (JSON ì¬ê·€ íƒìƒ‰)
# =============================
KB: Dict[str, Dict[str, dict]] = {}
for domain in ["yacht", "baseball", "gymnastics"]:
    domain_path = os.path.join(BASE_DIR, domain)
    if os.path.exists(domain_path):
        KB[domain] = {}
        for root, dirs, files in os.walk(domain_path):
            for fname in files:
                if fname.lower().endswith(".json"):
                    fpath = os.path.join(root, fname)
                    rel_path = os.path.relpath(fpath, domain_path)
                    try:
                        with open(fpath, "r", encoding="utf-8-sig") as f:
                            KB[domain][rel_path] = json.load(f)
                    except:
                        print(f"[Warn] JSON decode error: {fpath}")

# =============================
# ê²€ìƒ‰ í† í¬ë‚˜ì´ì¦ˆ
# =============================
def tokenize(text: str) -> List[str]:
    return [t.lower() for t in re.findall(r"[A-Za-z\uAC00-\uD7AF0-9]+", str(text))] if text else []


def score_doc_for_query(doc_text: str, query_tokens: List[str]) -> int:
    if not doc_text:
        return 0
    dtoks = tokenize(doc_text)
    dtokset = set(dtoks)
    score = 0
    for qt in query_tokens:
        if qt in dtokset:
            score += 2
        for dt in dtoks:
            if qt in dt:
                score += 1
    return score


# =============================
# ë„ë©”ì¸ ìë™ ë¶„ë¥˜
# =============================
def classify_domain(question: str) -> List[str]:
    q = question.lower()
    if any(k in q for k in ["ìš”íŠ¸", "laser", "470", "yacht"]):
        return ["yacht"]
    elif any(k in q for k in ["ì•¼êµ¬", "íˆ¬ìˆ˜", "í¬ìˆ˜", "baseball"]):
        return ["baseball"]
    elif any(k in q for k in ["ì²´ì¡°", "ë§ˆë£¨", "í‰í–‰ë´‰", "gymnastics"]):
        return ["gymnastics"]
    else:
        return ["yacht", "baseball", "gymnastics"]


# =============================
# KB ê²€ìƒ‰
# =============================
def retrieve_relevant(domain_kb: dict, query: str, top_k=3):
    qtokens = tokenize(query)
    hits = []

    for key, val in domain_kb.items():
        # JSON ì „ì²´ flatten
        def flatten(obj):
            if isinstance(obj, dict):
                return " ".join([flatten(v) for v in obj.values()])
            elif isinstance(obj, list):
                return " ".join([flatten(i) for i in obj])
            else:
                return str(obj)

        flat = flatten(val)
        score = score_doc_for_query(flat, qtokens)
        hits.append((score, key, val))

    hits = sorted(hits, key=lambda x: x[0], reverse=True)
    return [{"score": s, "key": k, "doc": d} for s, k, d in hits if s > 0][:top_k]


# =============================
# ìš”ì•½ ìƒì„±
# =============================
def summarize_doc(doc: dict) -> str:
    parts = []

    if "overview" in doc:
        parts.append(f"- {doc['overview']}")
    if "function" in doc:
        parts.append(f"- ê¸°ëŠ¥: {doc['function']}")
    if "wind_ranges" in doc:
        parts.append("- ë°”ëŒ ë²”ìœ„: " + ", ".join([f"{k}={v}" for k, v in doc["wind_ranges"].items()]))
    if "cunningham" in doc and isinstance(doc["cunningham"], dict):
        parts.append(
            "- ì»¤ë‹í–„ ê°€ì´ë“œ: "
            + ", ".join([f"{k}={v}" for k, v in doc["cunningham"].items()])
        )
    if "equipment" in doc:
        for k, v in doc["equipment"].items():
            desc = v.get("description", "") if isinstance(v, dict) else str(v)
            if desc:
                parts.append(f"- {k}: {desc}")

    return "\n".join(parts)


# =============================
# ìµœì¢… ë‹µë³€ í•©ì„±
# =============================
def local_synthesize_answer(query: str, retrieved: dict) -> str:
    found = False
    parts = []

    for domain, hits in retrieved.items():
        if not hits:
            continue
        found = True
        parts.append(f"--- {domain.upper()} ê´€ë ¨ ì •ë³´ ---")
        for h in hits:
            parts.append(summarize_doc(h["doc"]))

    if not found:
        return "ì£„ì†¡í•©ë‹ˆë‹¤, ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    parts.append("\nì¶”ê°€ ì„¤ëª…ì´ë‚˜ ì„¸ë¶€ ì •ë³´ê°€ í•„ìš”í•˜ë©´ ì–¸ì œë“ ì§€ ì•Œë ¤ì£¼ì„¸ìš”!")
    return textwrap.shorten("\n".join(parts), width=3500, placeholder="\n\nâ€¦(ìƒëµ)")


# =============================
# OpenAI ì—°ê²° (ì˜µì…˜)
# =============================
def openai_generate(system_prompt: str, user_prompt: str, api_key: str, max_tokens=512):
    if not openai:
        return None, "OpenAI íŒ¨í‚¤ì§€ê°€ ì—†ìŒ"
    if not api_key:
        return None, "API Key ì—†ìŒ"

    try:
        openai.api_key = api_key
        resp = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            max_tokens=max_tokens,
        )
        return resp.choices[0].message.content, None
    except Exception as e:
        return None, str(e)


# =============================
# API ì—”ë“œí¬ì¸íŠ¸
# =============================
@app.get("/")
async def home():
    html = os.path.join(TEMPLATES_DIR, "index.html")
    if os.path.exists(html):
        return FileResponse(html)
    return {"error": "index.html not found"}


@app.post("/query")
async def query_ai(req: Request):
    data = await req.json()
    question = data.get("question", "").strip()

    if not question:
        return JSONResponse({"answer": "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."})

    # í•œêµ­ì–´ ì§ˆë¬¸ í™•ì¥
    expanded = expand_korean_query(question)

    # ë„ë©”ì¸ ë¶„ë¥˜ í›„ ê²€ìƒ‰
    domains = classify_domain(question)
    retrieved = {
        domain: retrieve_relevant(KB.get(domain, {}), expanded)
        for domain in domains
    }

    # í•©ì„±
    answer = local_synthesize_answer(question, retrieved)

    # OpenAI ì‚¬ìš© ì‹œ ê°€ë…ì„± í–¥ìƒ
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        sys = "ë‹¹ì‹ ì€ Capstone Design ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•˜ì„¸ìš”."
        resp, err = openai_generate(sys, answer, api_key, max_tokens=400)
        if resp:
            answer = resp

    return JSONResponse({"answer": answer})
